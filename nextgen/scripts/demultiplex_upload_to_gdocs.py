#!/usr/bin/env python
"""Upload the information on the number of reads per barcode after demultiplex generated by the analysis pipeline to a spreadsheet on Google docs.

Given a tab-separated file of data generated by the analysis pipeline (typically WORKDIR/DATE_FCID_demultiplexed_read_counts.txt),
the title of a (pre-existing) spreadsheet on a GoogleDocs account (typically "YEAR MONTH Demultiplexed counts") and a base64-encoded 
string of the concatenated username and password (separated by a ':') for a google account with write access to the spreadsheeta, 
will create a new worksheet in the spreadsheet and enter the data into it. 

Usage:
    demultiplex_upload.py <demultiplex report file> <spreadsheet title> <Google account credentials (base64-encoded)>

The columns in the report file are assumed to be:

    date
    flowcell id
    lane
    description
    internal barcode id
    barcode name
    barcode sequence
    barcode type
    demultiplexed read count
    comment
"""
import os
import sys
import base64
import yaml
from optparse import OptionParser
from bcbio.pipeline import log
from bcbio.templates.bc_metrics import get_bc_stats

import gdata.spreadsheet.service
import gdata.docs.service

# The structure of the demultiplex result file on the form {title: column index}
header = [
          ['Project name','project_name'],
          ['Date','date'],
          ['Flowcell','flowcell_id'],
          ['Lane','lane'],
          ['Description','description'],
          ['Internal barcode index','barcode_id'],
          ['Barcode name','name'],
          ['Barcode sequence','sequence'],
          ['Barcode type','barcode_type'],
          ['Demultiplexed read count','barcode_read_count'],
          ['Comment','comment']
        ]

def decode_credentials(credentials):
    
    if not credentials:
        return None
    
    # Split the username and password
    return base64.b64decode(credentials).split(':',1);
    

def main(flowcell_id, gdocs_spreadsheet, gdocs_credentials, archive_dir, analysis_dir, gdocs_worksheet, append):

    # Split the username and password
    credentials = decode_credentials(gdocs_credentials)
    if not credentials:
        log.info("Could not decode GDocs credentials. No demultiplex counts were written to Google Docs")
        return
    
    # Get the GDocs demultiplex result file title
    if not gdocs_spreadsheet:
        log.info("Could not find Google Docs demultiplex results file title in config. No demultiplex counts were written to Google Docs")
        return
    
    # Get the barcode statistics
    fp = os.path.join(archive_dir, flowcell_id, "run_info.yaml")
    with open(fp) as in_handle:
        run_info = yaml.load(in_handle)

    fc_dir = os.path.join(analysis_dir,flowcell_id)
    bc_metrics = get_bc_stats(run_info,fc_dir)
    
    upload_demultiplex_data(bc_metrics,gdocs_spreadsheet,credentials,gdocs_worksheet,append)
    
    
def upload_demultiplex_data(bc_metrics, gdocs_spreadsheet, credentials, gdocs_worksheet=None, append=False):
       
    # Create a client class which will make HTTP requests with Google Docs server.
    client = gdata.spreadsheet.service.SpreadsheetsService()
    client.email = credentials[0]
    client.password = credentials[1]
    client.source = 'demultiplex_upload_to_gdocs.py'
    client.ProgrammaticLogin()
    
    # Create a query that restricts the spreadsheet feed to documents having the supplied title
    q = gdata.spreadsheet.service.DocumentQuery(params={'title':gdocs_spreadsheet, 'title-exact':'true'})
    # Query the server for an Atom feed containing a list of your documents.
    feed = client.GetSpreadsheetsFeed(query=q)
    
    # Check that we got a result back
    if len(feed.entry) == 0:
        log.info("No document with specified title '%s' found in GoogleDocs repository" % gdocs_spreadsheet)
        return
    
    # If we get more than one feed item back, will have to implement some way of resolving these
    if len(feed.entry) > 1:
        log.info("More than one document match the specified title '%s', will have to implement some way of resolving these!" % gdocs_spreadsheet)
        return
    
    # Get the matching spreadsheet entry from the feed    
    spreadsheet = feed.entry[0]
    ss_key = spreadsheet.id.text.split('/')[-1]
    log.info("Found spreadsheet matching the supplied title: '%s'" % spreadsheet.title.text)
    
    # Convert the bc_metrics data structure into a flat list
    rows = _structure_to_list(bc_metrics)
    
    # Set the default title of the worksheet to be a string of concatenated date and flowcell id
    if gdocs_worksheet is None:
        gdocs_worksheet = "%s_%s" % (rows[0][1],rows[0][2])
    
    # Write to the worksheet
    _write_to_worksheet(client,ss_key,gdocs_worksheet,header,rows,append)
    
def _write_to_worksheet(client,ss_key,ws_title,header,rows,append=False):
    
    # Check if there already is a worksheet present matching the data
    ws = None
    q = gdata.spreadsheet.service.DocumentQuery(params={'title':ws_title})
    feed = client.GetWorksheetsFeed(key=ss_key,query=q)
    # If there already exists one or more matching worksheet(s)
    if len(feed.entry) > 0:
        # If we're appending, do it to the last entry in the feed
        if append:
            ws = feed.entry[-1]
        # Else, add an enumerating suffix to the ws title
        else:
            ws_title += "(%s)" % (len(feed.entry) + 1)
    
    # If necessary, create a new worksheet for this run and add it to the end of the spreadsheet
    if ws is None:
        log.info("Adding a new worksheet, '%s', to the spreadsheet" % ws_title)
        ws = client.AddWorksheet(ws_title,len(rows)+1,len(header),ss_key)
        if ws is None:
            log.info("Could not add a worksheet '%s' to spreadsheet with key '%s'" % (ws_title,ss_key))
            return
    
    ws_id = ws.id.text.split('/')[-1]

    log.info("Adding data to the '%s' worksheet" % ws_title)
    # First, print the header
    # As a workaround for the InsertRow bugs with column names, just use single lowercase letters as column headers to start with
    for i in range(0,len(header)):
        client.UpdateCell(1,i+1,chr(97+i),ss_key,ws_id)
          
    # Iterate over the barcode stats and add the data to the worksheet
    for row in rows:
        row_data = {}
        for i,value in enumerate(row):
            row_data[chr(97+i)] = str(value)
        client.InsertRow(row_data,ss_key,ws_id)

    # Lastly, substitute the one-letter header for the real deal
    for i in range(0,len(header)):
        client.UpdateCell(1,i+1,header[i][0],ss_key,ws_id)

def _structure_to_list(structure):
    """Flatten all entries in the metrics data structure into a list of entry rows"""
    
    metrics_list = []
    for lane in structure:
        row = [""]*len(header)
        for i in range(0,5):
            row[i] = lane.get(header[i][1],"")

        for m in lane.get("multiplex",[]):
            for i in range(5,len(header)):
                row[i] = m.get(header[i][1],"")
                
            metrics_list.append(list(row))
            
    return metrics_list

def _apply_filter(unfiltered,filter):
    
    filtered = []
    for entry in unfiltered:
        passed = True
        for i,f in enumerate(filter):
            if f and entry[i] != f:
                passed = False
                break
        if passed:
            filtered.append(entry)
    
    return filtered

if __name__ == "__main__":
    usage = """
    demultiplex_upload_to_gdocs.py <flowcell id> <gdocs_spreadsheet> <gdocs_credentials>
                           [--archive_dir=<archive directory> 
                            --analysis_dir=<analysis directory>
                            --gdocs_worksheet=<worksheet title>
                            --append]
"""

    parser = OptionParser(usage=usage)
    parser.add_option("-r", "--archive_dir", dest="archive_dir", default=os.path.join(os.getcwd(),'store'))
    parser.add_option("-b", "--analysis_dir", dest="analysis_dir", default=os.getcwd())
    parser.add_option("-w", "--gdocs_worksheet", dest="gdocs_worksheet", default=None)
    parser.add_option("-a", "--append", action="store_true", dest="append", default=False)
    (options, args) = parser.parse_args()
    if len(args) < 1:
        print __doc__
        sys.exit()
    kwargs = dict(
        archive_dir = os.path.normpath(options.archive_dir),
        analysis_dir = os.path.normpath(options.analysis_dir),
        gdocs_worksheet = options.gdocs_worksheet,
        append = options.append
        )
    main(*args, **kwargs)
